---
layout: post
title: An Incomprehensive Guide to Consciousness
date: 2023-04-19
modified_date: 2023-11-26
publish: true
tags: ['consciousness', 'thoughts', 'universe', 'life']
excerpt: 
---



WIP DRAFT, YOU AREN'T MEANT TO BE READING THIS YET!  
… maybe i should make my posts into Part 1 and Part 2 next time so I can actually publish on time

## Preface

Consciousness is difficult. Humans have been arguing over what it means for thousands of years, and yet it seems to elude us, to be just out of reach.

So, instead of outright trying to define a precise and elegant solution that catches all the edge cases by some miracle, we'll instead search for the *vibe* of consciousness and cut down on the possible space of what it means. In more formal linguo, we'll note properties of conscious beings[^1] and some consequences of these properties. **Sounds like a much easier problem!**

The goal of this post is to effectively equip you with *tools of understanding* for conversations around consciousness — to give everyone a common starting framework —  and have a more visceral grasp on what it actually means. Selfishly speaking, I see too many conversations about this that are really just horrible in all sorts of manners — semantic misunderstandings, mismatched frameworks, or ill-formed opinions (there's differing opinions, and then there's bad ones). Everyone seems to have their own ideas yet they've thought about something for under 3 minutes and primarily sources their strange uncle's knowledge. We can do better. This serves as an attempt at converging conversations about consciousness and providing some base foundation, that can of course be modified, extended, torn apart, and dismantled as required.  Enjoy!


> And as a quick aside for ***that*** type of person: I don't really care if it's an "illusion" or not, or whether free will really exists, blah blah.  
**I experience**. I can feel pain, I can feel joy. I can punch people who say free will doesn't exist (not that I would, legally speaking) — perhaps they are correct, and that punch was premeditated by the beginning of the universe. Or simply a reflex of my brain to the given stimuli and that I indeed, did not exercise "free will" in that moment.[^2]

However, I do not care and can continue about my day, thinking about what I wish to and doing what I had planned.

And their face hurts now.  

## Properties of Conscious Systems

These ideas, in my eyes, aren't really disputable. Although they are a bit boring but nobody said fundamentals were fun! If you don't agree with something here, please mention why. Also, I do switch between consciousness and the mind sometimes here. Don't mind them — I'm effectively using these interchangeably.[^3]

### ![[Consciousness is physical and bound]]

There is nothing metaphysical about the human brain or consciousness — whatever it is, it's in your skull. That bounding box of 30cm x 30cm x 30cm. If you're feeling particularly peckish, we'll change the box to your body size to include the spine and the whole nervous system.

To me, the assumption of a metaphysical brain is a bit useless — it makes us say, "Welp. That's that," to a problem that isn't even solved. That's why I find the assumption that it *isn't magical* so alluring (also, I just don't see why we need to invoke extra complicated mechanisms when we might not even need them). Sure, there could in fact be some hidden property of conscious systems that no entity in the universe could observe or recreate, but we should at least extensively exhaust the possibility that *there simply are no hidden properties* first, right?

Of course, our talk here includes hormones, neurotransmitters, etc. Hormones in particular seem to function as a sort of "amplifier" over the whole network — having certain hormonal proportions changes the probability of certain actions/thought processes (thoughts can be considered as actions — actions that just map back INTO the brain instead of leaving it and telling your arm to go up). When you're angry for instance, adrenaline and cortisol start flooding you, your thinking is narrowed, your senses become acute, blood flow to your muscles increase in preparation for BATTLE. Physical! 

In the end though, it stays physical and tied within your body. It seems to be localised, even though it might not feel like it sometimes.

### ![[Consciousness is a spectrum#Consciousness is a spectrum]]
And I hinted at it above, but:  

### It's a spectrum too.
{ADD IMAGE HERE OF SPECTRUM?? LIKE.. BACTERIA, CAT/DOG, DOLPHINS, HUMANS, ....?????}
(also can ahve octopus somewhere random for fun).

Cats have it. Animals have it — have you seen a dolphin? Bacteria almost certainly don't.


Would you consider a human without an occipital lobe conscious? What about without their parietal?  Their prefrontal cortex? What if they had a bullet shot through, and they can't speak, but can communicate otherwise? What if they have alzheimers? What if they just didn't have a brain anymore? Okay, well looks like they need a nervous system. How about a dog? What about an octopus? Their nervous system isn't centralised and yet they exhibit clearly intelligent behaviour like puzzle solving.

After seeing a few videos of dogs suffering from *prolonged loss* after their owner's deaths, or the death of a sibling, it's quite difficult to say something like a dog doesn't have what we have in some manner. I use *loss* specifically because most of us *know* what that feels like, and it's hard to think that some entity experiencing that wouldn't be conscious (although I don't necessarily think that emotions as we have them are necessary for consciousness, but this belongs in speculation territory, not here). What feasible reason would a dog have to start refusing food after the death of their owner?? At the very least, it implies that something like a pet is a bit more complex than most people give them credit for.

It very likely doesn't exist at conception, and probably exists by the time you're 10. So somewhere between there, you 'gained' conscience! Not when you were a cell, probably not two cells, maybe when you learnt your first swear word. Congratulations, by the way. And yes, we are going ahead with "humans are conscious". Bite me.

An interesting conclusion of this property — there's no reason why we would be at the highest end of the consciousness spectrum possible. If conscience scales with perception and information processing, wouldn't we be more 'evolved' to *experience* better in a few million years' time, just as we evolved to gain increased awareness vs apes (to our knowledge), and other animals in the past few million years? Perhaps we are the "most conscious" entities in the universe *currently*, but we're almost definitely not at the absolute maximum (if there exists such a cap on consciousness).

I.e: There are higher order emotions you cannot reach, because your level of consciousness isn't sophisticated enough for them. Imagine the profound *sensation* you feel when you look at the night sky, without the light pollution of cities. All those complex emotions bound together by a simple curiousity. It's beautiful. And now, try to imagine something even more interwoven, more *significant*, than that. These are emotions that we cannot reach, due to a limitation in our range and quality of perceiving reality.


Think about it. We are a highly constrained system (with our brain operating at ~20W) evolved under natural selection pressures on Earth. This is definitely not min-maxed for brain power — our environment dictates that we still have to worry about other things — homeostasis, immune system threats, a whole barrage of physical threats, bad DNA replication; the list goes on. This is all to say we have to use energy elsewhere too.

Looks like we're on the spectrum!

### Consciousness is somehow related to perception

More specifically, it's related to the **quantity** **and** ***quality* of your perception** (of reality) — this is the bread and butter of consciousness. The whole thing revolves around experience right? A continuous subjective experience in reality. Creates. **You**.  

This sort of ties to illusions in a way — what is an illusion after all but simply when some of your perception disagrees with your other senses? If your **entire** perception is in agreement of something (say, a ball moving through the air — you can hear it move, feel the wind, see it spinning, …) then, that **is** your reality. There is no test, no movement, no action you can do to differentiate yourself from "true" reality. Because.

<center> Your (raw sensory) perception <b> IS your truth </b>. It <b>is</b> your reality. By definition. </center>

I cannot understate how important that sentence is (in general, and especially for future posts regarding potential futures of humanity).

If I were to give you *every* indication that you are on fire — you see flames on your skin, feel the burning agony of your cells, the smell of burnt hair, the correct amount of warmth penetrating your skin and heating your blood and internal organs; and your body reacting accordingly, adrenaline pumping, heart racing — then you are on fire. 

It's like the saying: "if it talks like a duck, acts like a duck,  fucks like a duck, (I forgot the quote) and quacks like a duck, it's probably a duck." 

Perception seems to be a necessity for consciousness, but it's likely not *sufficient* for it. You need perception yes, and you can become 'more' conscious if your quality of perception is increased, but you need other requirements. Like some type of information processing/manipulation system. 

#### Perception and Information

And this whole idea of consciousness scales with quality of perception ties to information since perception *is* information, right? So, perhaps the amount of information you can take and manipulate potentially determines the "maximum" level of consciousness you can attain, or at least places an upper bound on it?

For instance, simple bacteria can interact with their environment in few ways — they get some chemical signals, some heat in a certain direction — and then the machinery inside them chugs along and manipulates the bacteria to start accelerating its flagella in a certain way (as dictated by the machinery). So, it can't 'react' to that many different scenarios — its perception is low and only has a few signals to choose from. Its information bandwidth is low. So, I guess its level of conscience is low? (Let's remember that *just* perception alone is not enough to map to consciousness capability). 

Note: while changing physical machinery during a lifetime is hard (i.e, your arm does not change to wings when you need to fly), changing the program for *neural networks* (brains; *code*) can be a lot faster (you can learn to not jump off cliffs). All you need is energy. Which is probably why brains evolved — fast adaptability for complex algorithms (strategies) at the cost of high energy usage provided an evolutionary advantage, in that it allowed you to find exploitable patterns (say seasons, or animal/predator pathings, etc) to increase your fitness.

###### You are a biased network

This is partially related to conscience, partially related to the mind.

You are a biased network — or a biased system.

What I mean by this is very simple: you have a preference for what the state of the universe should be. And here, we suffer a bit from the english language, because one could describe an atom desperately wanting an electron to fill its outer shell as the atom having a "preference" for a state (where its outer shell is full), but I don't mean it like this.  
I mean 'prefer' in the way that we "prefer" being in a nice airconned room as opposed to being literally boiled alive, and not how the atom preferring to have its shell filled. Take that as you will. 

And of course, "prefer" is somehow defined by being a conscious/living entity under this framework, but I won't try to nail this definition further — you get the vibe. But yes, this property isn't so much a 'deduction into consciousness' as much as it is just an interesting idea we should keep in our minds.

*We are biased. We prefer the universe in certain states over others*, and that *this is different to atoms*. We clearly want SOMETHING over something else. And that's okay! We are allowed to have preferences — in fact, that's the interesting part! Just know that this is a side effect to our existence as a conscious entity.

## In the middle — The spice!

These ones — really just one thing — I'm fairly certain on, but it's not a given nor something I can be so certain about that it's a property above (although the above are more "consciousness-constraining properties" so we can reduce the bounding box of it). 

I want this one to be true, so I'm going to believe it[^4] because it's not been shown one way or the other. And the only way I'll believe otherwise is if this problem has been exhaustively (brute-forced) or concretely  found to be false[^5].

**Consciousness is substrate independent** — it can be digital.  Same with the mind/brain, since the whole idea of consciousness revolves around the processing of perception and information. Why would the mush of a brain, a configuration of carbon-based atoms and electrical impulses, be so much more special than silicon? Isn't computation transcendental to the material it is processed in?

In my old draft of this post I only mentioned substrate independence, but really that's just a symptom of a much larger property that's the root of all this:

## [[Consciousness is computable]]  

People's opinions on this are loaded, it's an unsolved problem and could go any way. I decided to make another post to go into this a bit more, but to sum up:  

I see no reason why the mind cannot be transcribed onto a digital interface. I.e the mind is Turing Complete, and also consciousness is Turing Complete as well. Yes, I'm including the effects of hormones and whatever else is required here too.

For me, it's hard to justify why one information processing system made out of *this* material would be more qualitatively powerful than another (Turing Complete) information processing system made of *that* material, when both materials exist in the real world. Especially since we have found no physical, actual model of hypercomputation in the world. And, what if both systems were made out of 'this' material, but the way they were instantiated was different? What then? 


And admittedly, if you haven't considered this before it's definitely odd to contemplate — how can something like a header reading/writing 0s and 1s be equal to us? But you should also consider how *much* we've been able to achieve using "just" this simple idea, that ends up being Turing Complete.

Perhaps it's from our nature to separate ourselves from other entities — that we are 'special' or 'unique' in some ways that nothing else can attain — we are the only 'intelligent' species, conscious, tool using creatures, etc… And when we look and look, we find that these unique properties are not so unique. Dolphins, orca, octupus (they don't even have a centralised nervous system yet can do tasks!). And from the above, I hope you agree with me that consciousness is a spectrum.


Anyways, I find this idea of general computability beautiful. It means that existence does not discriminate based on your material. You just need a system with the ability to process information in some certain ways, and boom. You get the privilege of **existence**.

Think about this for a second. We, atoms et al.[^6], have the unique privilege of a conscious existence within this gargantuan universe. The exceeding majority of atoms and energy do *not* have this luxury! They simply exist, without being able to *feel their existence*. But if these ideas of the Church Turing thesis are right — if consciousness is in fact computable, and that we are not 'unique' in the way that we are the only thing capable of experiencing it — we can give it to non-conscious atoms.

We can put forth our hands to the desolate areas of the universe, to dead rock and martian grass, and we can offer them a handshake to *the ability to exist **and feel it***. We can offer them consciousness, by using them to create conscious systems. 

Even eating is a process of converting non-conscious atoms to conscious ones. Seriously. I mean, half of us probably wouldn't be alive if the [Haber process](https://ourworldindata.org/how-many-people-does-synthetic-fertilizer-feed#:~:text=As%20a%20result%2C%20the%20Haber,to%203.5%20billion%20people%20today.) wasn't found.

Also, it just makes things a lot simpler. No need to create suspicious ideas to allow for consciousness; it just becomes a mystery of computation that we haven't figured out yet.

### Break Time!!

Okay, how's your attention span going? If you're good, then just read ahead. Otherwise, stop here for a quick break & attention reset. Surprise cat!  
Derpy cat:  
![Image Description](/assets/obsidianposts/cat.png)  
A cat on the hunt:  
![Image Description](/assets/obsidianposts/cathunt.png)  
A strange looking cat:  
![Image Description](/assets/obsidianposts/dogjump.png)  
In the past, I've enjoyed [Seycara](https://www.youtube.com/c/seycara) and [Rush Garcia's](https://www.youtube.com/@RushGarcia) (older) songs. It's just, relaxing. Seycara had a mix of electronic orchestral(?) going, and it felt nice with the studio ghibli remixes he did.

Feeling refreshed? Let's get into the spicier, but also more rewarding ideas now.

## More 'disputable' ideas

These ideas, I do not hold such strong attachment to and would be willing to change my beliefs on them if good counterevidence was provided. However. They are **very cool!**

For now, they make sense to me and I construct some toy examples to shows something of the sort can be mathematically true, as a sort of "It is possible".

I *really* like the next two ideas:

### Recursion is key

Surely consciousness has *something* to do with recursiveness, to create that illusion of self over spacetime.
![Image Description](/assets/obsidianposts/recursion.png)
It seems very plausible that conscience somehow occurs through the loop — that some subset of the outputs from your model is fed back into the input again — which enables us to string together our experiences and perception into a cohesive tapestry over time that we call consciousness.

After all, the whole idea of consciousness is a ***narration*** of your existence — your **continuous existence over time, as a single self** — surely that requires some recursive properties, no? To maintain the **self**? 

We know for a fact that our brains do not shut off until we *die*, and that the architecture our brains have is in that an RNN — a *recurrent* neural network (recursive!!). Although it is interesting that we often lose our consciousness — most people do it every night with this activity called "sleep". And yet, we wake up and still *feel* like we are the same entity, the same person, *even though there's a discontinuity between the two*. So, we just assume that we are the same person. 

 I'd perhaps go as far as to say that this sort of recursive structure is *required* for a being to be conscious. Maybe not sufficient by itself, but required. Some subset of your outputs must map back into your inputs (we just so happen to call these "thoughts"). In other words: your entire mental output consists of thoughts (which are fed back into your mind), along with the external actions you act upon your (external) environment. 

##### Continuing on this output/input idea

Perhaps it is not just the information flow, but also how this info is *compressed* into that output->input tube that has something to do with constructing consciousness?

Again, how far can we go with this concept? Perhaps the output/input "recirculation" ratio is actually really important for conscious systems — a higher ratio with larger information bandwidth could be indicative (along with other factors) of a more 'conscious' entity. An upper bound of sorts.

Although we wouldn't want to have too much — at a ratio of 1, you'd end up with a system that's just trapped in itself! It has no way to interact with the environment (although it could potentially take inputs from it), which sounds awful and quite sad, so let's not do that one (but you potentially could "listen" into its thoughts with the right probes in the right places).

Perhaps some of these ideas completely miss the mark, and that's fine — I'm only presenting ideas at this stage! That doesn't mean they're right or wrong — just that they might be worth considering. Let your mind wander, foo(l)! It would be extremely bland and boring if this was just a rehash of all very well known ideas to everyone that offered no food for thought.

#### How in-built must recursion be to the system?

One question that appeared when I was thinking about recursion was: How  ingrained does recursion need to bein the system for it to propagate its continuity (conscience)?

Does the architecture itself need a recursive section? Like an RNN.  
  
Or is something like a transformer enough, provided that there is always some subset of its outputs  are interpreted as the next iteration's input. You could do this by (for instance, assuming a text-output transformer) keeping a specific section of a text prompt as a designated "Thoughts/Continuity" area, and this section is always fed back into the transformer whilst the rest of its output is whatever is required. 
  
Thinking about this, we see that the main difference is the rate of output-> input.

Relating to our recursion point above — maybe, for a non-recursive architecture, it *could* be possible, but only in the forward pass? Or its 'instance of consciousness' is so messed up — the continuous experience of its existence, forcefully jaded at the end of its pass — that it becomes a sad state of affairs. {FIX, I MOVED THIS FROM THE THE CONSCIOUS INTELLIGENCE BIT BECAUSE IDK WHY IT WSD THERE, BUT I MIGHTVE TALKED ABOUT THIS ALREADY}  

##### A tangent that resolves itself — Architectures

However, what if thinking linearly like this is insufficient? What if, instead of only some output nodes connecting to the input, we also have some hidden layer nodes connect to the input?  
This is somewhat more akin to how our brain works, although I don't know if this has been done before.  
Actually, how does our brain work?? Aren't the only output layers in fact the ones that map to physical action, and other layers also contain outputs…? Or does it not matter, and you can 'unwind' a 3D graph into an equivalent 2d one, i.e they the same? Graph theory heeeelp.

> Can you unwind (i.e, without changing connections etc…) the brain into a typical neural feedforward network, i.e can the graph topology of a brain be represented/be mathemtaically equivalent to some forward-feed NN (as is the case of transformers, …)? Or do you need to have some NN that can have its weights at layer L have connections to L+2 onwards instead of just the exact next layer?  
> 	Another way of thinking about this that goes away from the brain is — say we have some NN graph structure that's stored in 3D on a computer (i.e connects the same way as a brain, naively speaking). Is there always an equivalent feed-forward NN for any such structure?

> Of course, when I think about this more, haven't we already answered it? [An RNN]( https://www.ibm.com/topics/recurrent-neural-networks#:~:text=A%20recurrent%20neural%20network%20),  for instance. And this of course, is different to a feed-forward network. But are the *capabilities* of an RNN inherently different to that of a feed-forward network? I… feel like there might not be, as I allude to in my next segment (other than perhaps its ability to be conscious).[^7]

### Intelligence != Consciousness

As Demis Hassabis said, "I think intelligence and consciousness are double-dissociable".


I think that general Intelligence (the ability to seek & achieve goals, and how competent it is at doing so (where there is imperfect information about the system the entity resides))[^8] is tied to consciousness, but not necessarily super coupled together. 

What I mean by this: you can have an extremely intelligent but non-conscious agent, although it's likely harder to keep them apart as general intelligence increases (general, as opposed to narrow intelligence in some domain like chess[^9]). 


I'm about to say something a bit out there, and it's just a thought I had now (and have since ruminated on for a few months) ~~so I don't know too much about it~~: 

**Conjecture:** Perhaps *anything that a conscious intelligent system could do, a non-conscious yet still intelligent one could do aswell.*[^10]

#### A Thought Experiment On Black Boxes

 Let's consider a thought experiment[^11] with functions: 
 - You have two black boxes B1 and B2, and for every possible input, B1 yields the same output as B2. For **every possible input**.  
However, the internal processes that occur inside these black boxes are different.  
[image here. two boxes with an input pipe and output pipe. maybe have a funny illustration of like, you input food and you output "gaseous particles" (farts)]
![[An Incomprehensive Guide to Consciousness November 27, 2023.excalidraw]]

Let's use a simple mathematical abstraction: $$f(x) = \frac{x^{3}}{x}$$ vs $$g(x)= \frac{x^{4}}{x^{2}}$$ for our B1, B2. Different intermediary transformations occur on our input, but in the end, the functions map every possible input of their (equivalent) domains to the same outputs ([From this](https://discord.com/channels/813324385179271168/813325735620116490/1104979343731593256)). This means that really, they behave like the *same function* -- their outputs are the same for any given input.  

So now we have two systems that respond the exact same way to all given stimuli, and yet their internal workings are different. That's the beauty of functions after all — it's just inputs and outputs. And of course, now we simply extend this thought experiment so that our black boxes are intelligent systems (like us!). The inputs are arbitrary, the outputs are arbitrary. Functions are general and beautiful. 

We see that (because I like writing and fancy wooo woo metaphors) even if the *destination is the same*, the intermediate processes (journey) can lead to different intermediary results. And whilst you could simplify the two in the simple example to be the same via algebra, in an actual physical system, *they aren't the same*. Say for instance that to implement our functions in reality, we do all our multiplications before divisions[^12]. x * x * x vs x * x * x * x. We see that our f(x) will **never** have an opportunity to reach some stage where an $$x^{4}$$ occurs, even if f(x) and g(x) are the "same". Aka our function can enter a completely different state before ending in the same result.

(HAVE THE TWO BLACK BOXES PIC AGAIN, BUT NOW WE CAN SEE THE INTERNAL WORKINNS, AND HOW THEY ARE DIFFERENT HET YIELD THE SAME RESUTL (I guess each X can be move up a lev inside the chamber, each divide down, and in the end they both go out the same level but how they got there is different)

They are equal in **output**, but not equal in **process**.

Of course, we can extend this analogy to conscious systems. We imagine the entities as black boxes, where we provide inputs (like light, heat, audio, or direct electrical signals) and read some designated output. And so, perhaps there are intermediary processes that are instrumental in forming consciousness, and that only occur in certain information transfer architectures and not others?

To recap: within the black boxes, the conscious system could reside. Or it doesn't. But only it knows. From the outside, we see both of them as equivalent. They're black boxes, and they behave the same. *But they aren't the same*. It's not just the destination, but the journey that matters too.[^13] 

Now, if this statement was strong enough, it leads to a slightly unsettling consequence (not actually: see next paragraph) — namely that, if there is some entity that, no matter what test you give it (all possible tests), you cannot tell whether it is conscious or not.

Oh dear.

So, this would mean that the only entity that would know whether the black box system is conscious or not is… itself. Now, I'm not sure whether I agree with this — there must be some sort of prodding you could do to tell whether a system is conscious or not — I mean, after all, how the hell would we figure it out?  

> Well, you would be right, me from the past! 

On further thought, if you had access to the information processing system (architecture) of an entity — its neural network, weights, architecture, connections, whatever it may be — there'd be no reason why you wouldn't be able to discern which system has consciousness if this phenomena does indeed arise out of specific patterns in how it processes information (say, for instance, a certain threshold of output/input ratio neurons[^14],  etc…).  

Relating to our simple example for f(x) and g(x), we could tell that f(x) would never be able to reach $$x^{4}$$ whilst g(x) could — that's a property!  We could attribute lower powers to be more likely in conscious entities (for compression/efficency or something), so the system that holds f(x) is more likely to be conscious. Kinda like that, but, y'know, with actual reasoning and sense into it applied onto the complex data transformations that occur to real entities. After all, our function examples serves as a simple intro for explanatory purposes. 

(SHOW THAT BLACK BOX IMG AGAIN, just annotate how like "If we somehow know that this type of transformation of X and reaching a certain level is indicative of consciousness, we can see that g(x) has "more conscience" (since it is likely a spectrum, as we've discussed)).

*However*, this still means that for our two systems B1 and B2, one conscious and one not, unless you look at what's *inside* and how the information flows through, they could both output the same as each other with the non-conscious agent perfectly "imitating" the conscious one for all inputs. And you'd never know which one was conscious.
(have an iamge of B1, B2 but with multiple inputs past just the simple function, like "Food", "thoughts", etc...) with the conscious one being all cool and shit, non-conscious being like oh yeah. But in the end, they're both output the same thing
#### Consequences of these ideas and assumptions

Based on the properties that we've talked about before, there are some few consequences we can find from these (which so happen to also be properties, just not assumption/base-level properties).


- If there exist digital representations of consciousness (conscience is turing complete), then this naturally means that duplication of conscious systems is possible. This is a *very weird* idea, but it's just a consequence, like how your experience of time *physically changes* depending on your relative velocity  due to relativity (time dilation!). If you can in fact store the program of yourself and its data, then, shouldn't you be able to copy it?  And now you'd have 2 equivalent, distinct copies of yourself. If you fed it different data, it'd evolve in different ways — you could plant each version inside a different body with sensory experiences, and it would start off as two identical copies (which can obviously interact with each other), but as their experiences change over time, so would they.
- Due to the locality of consciousness, you get this nifty thing I call [[The Concept of You]]. Like all concepts one thinks is original, it turns out I did not invent this. There is a very similar concept called "The egg", and [Kurzgesagt has a video on this.](https://www.youtube.com/watch?v=h6fcK_fRYaI) I'll post my version of it when I finish it (lol).

There are some minor ones like [[merging of conscious entities]], but I don't feel as confident on these so I'll leave it just as a mention.

## Conclusion

Basically, the three most important points you should take away are:
1. Your raw sensory perception (+ thoughts) of reality IS reality
2. You are a biased network/system, with a preference for how the universe should be
3.  Consciousness is computable

The third one is not a god-given obvious one, but it makes everything a lot cleaner and a lot less 'magicky'. Even if the 3rd one were to not be true, certain endgames could still occur. Hopefully this post has given you some food for thought, and you leave with at least some new ideas to ponder.  
Feel free to discuss in the comments :)

Adios!

#### Author's Notes

Wow.

This was meant to be a simple post, and in fact the least intensive and easiest to write post of my main ideas. This was meant to be a primer into some future posts I'm making, about endgames of humanity and my view on what the best endgame could be.

It seems I've greatly underestimated by ability to procrastinate. Anyways, hopefully some of these ideas have made you think; that's all I ask for. GG!

[^1]: I've always used the phrase 'conscious entities' since I prefer it but now I notice that 'beings' is one syllable and I don't really have a good excuse not to use it… 'Being' also gives some hint as top what everyone understands about conscience — it's about being, about experiencing.
[^2]: This isn't to say that habits have no value — habits have tremendous value, but I must stay on topic. Why do I feel the need to write this elaboration down? Who's cancelling me - I'm not even known!
[^3]: But just to make it clear, I think the mind harbours consciousness, where the mind is some information processing system. Consciousness can't exist without information transfer.
[^4]:   Notice how I'm calling this out instead of just throwing it up there and stating it as fact? Crazy, right?
[^5]: Yeah… I'm stubborn on this one, sorry. It brings me much joy and will to live for it to be the world we live in.
[^6]: I say this because it seems like humans are initialised with more than just pure DNA and atoms — information seems to be stored on surface electricity on membranes and shit? This guy -> [Michael Levin](https://www.youtube.com/watch?v=p3lsYlod5OU). (and Nick Lane while we're at it. Yes, perhaps a non-trivial amount of my biology information comes from them and a few books, but that's pretty high quality information all round, no?)
[^7]: Finally a good segway into the next part haha.
[^8]: Turns out intelligence suffers the same definitional issue that consciousness has… Who would have thought?
[^9]: — Well, I guess we can define general intelligence as "narrow intelligence", but in the domain of the universe (our reality). Hmmm… What's a good definition for the Level of intelligence – I’m trying to think of something that’d separate something like being super-good in chess to being good at life..? Humans, dogs, etc… Ability to solve problems that were originally outside the scope of your system? To gain understanding of systems outside your current knowledge pool?). Well shit, my train of thought just derailed. Where were we?
[^10]: Note that I don't make any statements about the efficiency of achieving said goals, just the capability of doing it. Maybe consciousness makes goal-completing more efficient in terms of energy usage, who knows?
[^11]: Thought experiments (those that have SIMPLE and CLEAR assumptions that lead to intriguing insights) are really cool
[^12]: The argument works even if the order is random (but still obeys order of operations).
[^13]: Stormlight archive, anyone?
[^14]: If you did in fact need recursion in the architecture for consciousness